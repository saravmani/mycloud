Hugging face 
    Transformers pipeline
    Diffusion Pipeline - image generation
    Tokenizer

Quantizing- process of reducing the precision of the numbers that represent model parameters and activations. This reduction can significantly decrease the model's memory footprint and computation requirements, making it more efficient, especially for deployment on resource-constrained devices like mobile phones 